<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ML Instant House Valuation: Part 1 - Analysis | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="ML Instant House Valuation: Part 1 - Analysis" />
<meta name="author" content="Uzair Patel" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A-Level computer science project" />
<meta property="og:description" content="A-Level computer science project" />
<link rel="canonical" href="https://uzair223.github.io/posts/house-prices/2022/05/08/p1-analysis.html" />
<meta property="og:url" content="https://uzair223.github.io/posts/house-prices/2022/05/08/p1-analysis.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-05-08T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ML Instant House Valuation: Part 1 - Analysis" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Uzair Patel"},"dateModified":"2022-05-08T00:00:00-05:00","datePublished":"2022-05-08T00:00:00-05:00","description":"A-Level computer science project","headline":"ML Instant House Valuation: Part 1 - Analysis","mainEntityOfPage":{"@type":"WebPage","@id":"https://uzair223.github.io/posts/house-prices/2022/05/08/p1-analysis.html"},"url":"https://uzair223.github.io/posts/house-prices/2022/05/08/p1-analysis.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/posts/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://uzair223.github.io/posts/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/posts/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/posts/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/posts/about/">About Me</a><a class="page-link" href="/posts/search/">Search</a><a class="page-link" href="/posts/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">ML Instant House Valuation: Part 1 - Analysis</h1><p class="page-description">A-Level computer science project</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-05-08T00:00:00-05:00" itemprop="datePublished">
        May 8, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Uzair Patel</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      18 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/posts/categories/#house-prices">house-prices</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/uzair223/page/tree/master/_notebooks/2022-05-08-p1-analysis.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/posts/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/uzair223/page/master?filepath=_notebooks%2F2022-05-08-p1-analysis.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/posts/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/uzair223/page/blob/master/_notebooks/2022-05-08-p1-analysis.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/posts/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fuzair223%2Fpage%2Fblob%2Fmaster%2F_notebooks%2F2022-05-08-p1-analysis.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/posts/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#Background">Background </a></li>
<li class="toc-entry toc-h2"><a href="#Current-systems-analysis">Current systems analysis </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Zoopla">Zoopla </a></li>
<li class="toc-entry toc-h3"><a href="#Yopa">Yopa </a></li>
<li class="toc-entry toc-h3"><a href="#OnTheMarket">OnTheMarket </a></li>
<li class="toc-entry toc-h3"><a href="#End-User-Questionnaire">End User Questionnaire </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Problem-Modelling">Problem Modelling </a></li>
<li class="toc-entry toc-h2"><a href="#Algorithms">Algorithms </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Conformal-prediction">Conformal prediction </a></li>
<li class="toc-entry toc-h3"><a href="#Stochastic-gradient-descent-and-linear-regression">Stochastic gradient descent and linear regression </a></li>
<li class="toc-entry toc-h3"><a href="#Multilayer-Perceptron">Multilayer Perceptron </a></li>
<li class="toc-entry toc-h3"><a href="#Backpropagation-algorithm">Backpropagation algorithm </a></li>
<li class="toc-entry toc-h3"><a href="#CART-algorithm">CART algorithm </a></li>
<li class="toc-entry toc-h3"><a href="#Random-forest">Random forest </a></li>
<li class="toc-entry toc-h3"><a href="#Gradient-boosting-machine">Gradient boosting machine </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-05-08-p1-analysis.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Background">
<a class="anchor" href="#Background" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background<a class="anchor-link" href="#Background"> </a>
</h2>
<p>I will be creating a house valuation web app which will allow a user to input a set of property features (such as the number of rooms, floor size, property age etc.) and be given an instant valuation based on a machine learning solution. The idea began by brainstorming a number of machine learning related tools; first a weather forecasting tool, then a stock price predictor, but finally I settled with a house price valuation tool. I found it more interesting and challenging to be forced to build, analyse and develop a solution myself, as I could not find material/tutorials for this project online, unlike the many tutorials available for weather nad stock. The project began more as a research task but I decided to develop it as a web service, after stumbling across this <a href="http://diamonds.foostack.ai/">Diamond price prediction project</a> (now inactive) online.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Current-systems-analysis">
<a class="anchor" href="#Current-systems-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Current systems analysis<a class="anchor-link" href="#Current-systems-analysis"> </a>
</h2>
<p>To get an idea of how my system should function, I will take a look at popular pre-existing house valuation tools. Ideally I would like an indication to the data and methods the tools use, however it is unlikely that I will be able to. The UI and aesthetics is not my main concern in the analysis, but I will also follow and expand on some of the design components that are similar between them all.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Zoopla">
<a class="anchor" href="#Zoopla" aria-hidden="true"><span class="octicon octicon-link"></span></a>Zoopla<a class="anchor-link" href="#Zoopla"> </a>
</h3>
<p><img src="/posts/images/copied_from_nb/images/zoopla-01.jpg" alt="">
<img src="/posts/images/copied_from_nb/images/zoopla-02.jpg" alt="">
<img src="/posts/images/copied_from_nb/images/zoopla-03.jpg" alt=""></p>
<p>I like Zoopla's system as it is very simple to use and understand, its UI is visually appealing, and it includes other data apart from just the valuation, such as local amneties, making it even more helpful to an end user.
The Zoopla valuation uses data already on its databases to instantly valuate the property. Its additional data sources, such as the HM Land Registry, are also provided, which is ideal for my problem as it will allow me to explore and potentially use datasets from the same reliable sources.
Unlike Zoopla, I will adopt a system where the end user is asked for the property’s location as well as other property features, such as its total square footage etc., which allow for the valuation of properties that possibly don’t even exist. Additionally, I will provide the last sold price if the input property does exist, similar to how Zoopla does.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Yopa">
<a class="anchor" href="#Yopa" aria-hidden="true"><span class="octicon octicon-link"></span></a>Yopa<a class="anchor-link" href="#Yopa"> </a>
</h3>
<p><img src="/posts/images/copied_from_nb/images/yopa-01.png" alt="">
<img src="/posts/images/copied_from_nb/images/yopa-02.png" alt=""></p>
<p>I like the simplicity of the Yopa valuation, however only requiring the number of bedrooms and location doesn't seem like it would yield a very accurate result. In my system, I would ideally require at least 5 features for the resulting estimation. Yopa, similar to Zoopla, also implements a low and high estimation alongside its valuation, and I will also attempt to implement this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="OnTheMarket">
<a class="anchor" href="#OnTheMarket" aria-hidden="true"><span class="octicon octicon-link"></span></a>OnTheMarket<a class="anchor-link" href="#OnTheMarket"> </a>
</h3>
<p><img src="/posts/images/copied_from_nb/images/onthemarket-01.png" alt="">
<img src="/posts/images/copied_from_nb/images/onthemarket-02.png" alt="">
<img src="/posts/images/copied_from_nb/images/onthemarket-03.png" alt=""></p>
<p>I particularly like the UI and aesthetic which OnTheMarket's online valuation system uses. The predicted prices seem to be based on location averages, which I may also implement in my system alongside the machine learning aspect. Additionally, the system requires 15 features in addition to the location, which makes the valuation seem more accurate to the end user, unlike the Yopa valuation which only required the number of bedrooms. I will however reduce the number of required features, and keep all my parameters on a single page, to make the process somewhat easier. I will source data which includes similar features such as the property age, number of rooms, property type etc.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="End-User-Questionnaire">
<a class="anchor" href="#End-User-Questionnaire" aria-hidden="true"><span class="octicon octicon-link"></span></a>End User Questionnaire<a class="anchor-link" href="#End-User-Questionnaire"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I asked 3 home-owners questions on their thoughts of the project and how I should develop it; I think the responses of potential users will be particularly helpful in the direction of which the development of my project goes:</p>
<ol>
<li>
<p>Would you consider an online property valuation as an accurate way to get the price of a property?</p>
<ul>
<li>
<em>Response 1:</em> I would consider an online valuation to get a rough idea of a house's value. I would probably use a tool like this before contacting an estate agent to valuate the property in real life.</li>
<li>
<em>Response 2:</em> I'd use an instant valuation tool to see if a property is worth pursuing, it would save a lot of time instead of having to contact somebody myself.</li>
<li>
<em>Response 3:</em> I don't think a service like this would be highly accurate but I do think it would give a useful estimation and could give a relatively reliable prediction.<hr style="width:0;">
</li>
</ul>
</li>
<li>
<p>What characteristics of a property do you think would most impact its valuation?</p>
<ul>
<li>
<em>Response 1:</em> I think the age, size and property type would be useful in telling the price of a house. However, I believe the value of properties in the area would have greatest impact on a house's price.</li>
<li>Response 2: The price of surrounding properties would be the most useful in the valuation of a house, along with its total square footage, number of rooms, and perhaps general local area information like population and crime rate.</li>
<li>
<em>Response 3:</em> The quality of the neighbourhood of a property and the prices of other houses nearby are the most indicative of a property's value. Property features such as the size and the type also impact a property's valuation greatly.<hr style="width:0;">
</li>
</ul>
</li>
<li>
<p>What additional features would you like to see, alongside the valuation?</p>
<ul>
<li>
<em>Response 1:</em> I'd like to see the average price of houses in the local area, or perhaps the average price of similar property types.</li>
<li>
<em>Response 2:</em> I think it'd be helpful to see local area statistics such as the population and average house price in the area. Additionally, I don't think a point estimation is a very helpful so I'd like to see an valuation with an associated interval, with a low and high estimation.</li>
<li>
<em>Response 3:</em> It would be interesting to get predictions for the price of a property years in the future. It would also be helpful to see the previous sold price of a property.<hr style="width:0;">
</li>
</ul>
</li>
<li>
<p>How would you like the information displayed to you?</p>
<ul>
<li>
<em>Response 1:</em> I'd like to see the information displayed as simply as it can, clutter and unnecessary information can be quite annoying - like asking for email and other data that has nothing to do with the actual predictions. I would prefer all the information easily visible in one window.</li>
<li>
<em>Response 2:</em> I think displaying a map of the property's area along with its valuation would be helpful, especially for people who consider moving into the area. There should be an option to have the predictions emailed to you, but not as a requirement.</li>
<li>
<em>Response 3:</em> A simple web form should suffice for inputting the property details. The output could be given in a separate page or pop-up with all the information.<hr style="width:0;">
</li>
</ul>
</li>
</ol>
<p>In conclusion, the home-owners would consider using the service as a <strong>rough estimate</strong> for a property's value <strong>before seeking professional advice</strong>. All 3 participants think that local area information could be useful in the valuation, as well as the property size and type. I liked the idea to include local area statistics in the output to the user, and I agree that unnecessary clutter should be avoided when serving the information to the end user.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Problem-Modelling">
<a class="anchor" href="#Problem-Modelling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problem Modelling<a class="anchor-link" href="#Problem-Modelling"> </a>
</h2>
<p>My initial thoughts on how to approach the problem.
I will try implement the system in four (or potentially five) stages:</p>
<ul>
<li>
<em>Stage 1.</em> Data sourcing - collecting and stitching data from various sources to build a large dataset (aiming for around 1 million rows).</li>
<li>
<em>Stage 2.</em> Data sanitisation and preprocessing - transforming the dataset and its features to allow for predictive modelling</li>
<li>
<em>Stage 3.</em> Model training - testing and training various machine learning models on the dataset to maximise accuracy</li>
<li>
<em>Stage 4.</em> Web development - implementing the server and client side for users to access.</li>
<li>
<em>(if possible) Stage 5.</em> App deployment - deploying the client-server model to the web for potential use.</li>
</ul>
<p>Below covers the general implementation and structure of the project, split into its distinct stages.</p>
<p><img src="/posts/images/copied_from_nb/images/ml-workflow.png" alt="">
<img src="/posts/images/copied_from_nb/images/uml-draft.png" alt=""></p>
<p>I am currently unclear on what machine learning models to use and how to preprocess the data. These decisions will be made as the data is collected and in exploratory data analysis. I will fit multiple models on the dataset and test their performance to pick an algorithm, I may also ensemble/stack multiple models if it proves useful. I may need a database for features of the model which require context from the inputs provided by the end user, such as geospatial or local area data.</p>
<p>The web service itself, which will serve the predictions to the end user, will look somewhere along the lines of:</p>
<p><figure>
  
    <img class="docimage" src="/posts/images/copied_from_nb/images/interface.png" alt="" style="max-width: 400px">
    
    
</figure>
</p>
<p>Drawing inspiration from the Zoopla and OnTheMarket user interfaces, with a simple form, an interval prediction, and a map of the area using Google Maps API.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Algorithms">
<a class="anchor" href="#Algorithms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Algorithms<a class="anchor-link" href="#Algorithms"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conformal-prediction">
<a class="anchor" href="#Conformal-prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conformal prediction<a class="anchor-link" href="#Conformal-prediction"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Conformal prediction is a technique used to assess the uncertainty of predictions produced by a machine learning model. In particular, given an input, conformal prediction estimates a prediction interval in regression problems and a set of classes in classification problems. Both the prediction interval and sets cover the true value with high probability (usually provided by the user).
Steps to producing a conformal prediction model:</p>
<ol>
<li>Identify a score function to measure the discrepancy between model outputs $\hat y$ and expected outputs $y$. This metric is critical as it decides what prediction sets can be obtained. For instance, in regression problems, we could take the absolute error $|\hat y - y|$ as the score function.</li>
<li>Compute nonconformity scores for the model by splitting the training set into a proper set and calibration set. The model is only trained on the proper training set; and scores are computed on the calibration set where $S_n = S(\hat y_n, y_n)$ for the $n$<sup>th</sup> sample.</li>
<li>Prediction - use the underlying algorithm to make a point prediction $\hat y$ and take the ($1 - \alpha$)<sup>th</sup> quantile $Q$ from the score set - where $\alpha$ is a user-provided significance level. Output $\hat y \pm Q$ as the model's prediction.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Stochastic-gradient-descent-and-linear-regression">
<a class="anchor" href="#Stochastic-gradient-descent-and-linear-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stochastic gradient descent and linear regression<a class="anchor-link" href="#Stochastic-gradient-descent-and-linear-regression"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Regression models are used to describe relationships between variables by fitting a line to the observed data. Multiple linear regression is used to estimate the relationship between multiple independent variables and one dependent variable. The model makes assumptions about the dataset:</p>
<ul>
<li>
<p><strong>Homogeneity of variance (homoscedasticity)</strong> - the observations in the dataset must be about the same distance from the regression line.</p>
<p><img src="images/homoscedasticity.png" alt=""></p>
</li>
<li>
<p><strong>Independence of observations</strong> - there are no hidden relationships among independent variables.</p>
</li>
<li>
<strong>Normality</strong> - the data follows a normal distribution.</li>
<li>
<strong>Linearity</strong> - the line of best fit through the data points is a straight line, not some polynomial/exponential curve</li>
</ul>
<p>Multiple linear regression generalises a dataset as the output being a weighted summation of its inputs.
$$
\hat y_i = b + \sum^n_{k=0} w_k x_{ik}\\
$$
In matrix form, it can be written as a dot product, as shown:
$$
\hat y = w\cdot x + b
$$
Where,<br>
$\hat y$: predicted<br>
$x$: independent variables vector<br>
$w$: coefficients vector i.e weights<br>
$b$: constant term i.e bias</p>
<p>The stochastic gradient descent algorithm is used to adjust the weights and bias for the model. The algorithm requires a differentiable cost function in order to derive the gradients of each adjustable parameter. I will be using the <strong>half mean squared</strong> cost function, as it will differentiate nicely making it a lot easier to implement. The cost function is defined as such,
$$
J(w,b) = \frac 1{2n}\sum_{i=1}^n(wx_i + b - y_i)^2
$$
The goal is to find the values of the $w$ and $b$ terms which minimise the error. This can be done by taking the partial derivative (gradient) of the cost function $J$ with respect each parameter,
$$
\frac {\partial J}{\partial b} = \frac 1n\sum_{i=1}^n (\hat{y}_i - y_i) \\
\frac {\partial J}{\partial w} = \frac 1n\sum_{i=1}^n x_i(\hat{y}_i - y_i) = \frac 1n x \cdot (\hat{y} - y)
$$
Where $\eta$ is the learning rate, iteratively update the parameters until they converge,
$$
  b := b - \eta \cdot \partial b \\
  w := w - \eta \cdot \partial w 
$$</p>
<p>The implementation of linear regression with stochastic gradient descent will be a great starting point when implementing the more complex multilayer perceptron model, which similarly uses the weighted summation function to make predictions and a gradient descent algorithm to optimise its parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multilayer-Perceptron">
<a class="anchor" href="#Multilayer-Perceptron" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multilayer Perceptron<a class="anchor-link" href="#Multilayer-Perceptron"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A multilayer perceptron is a feed-forward neural network consisting of at least three layers of nodes; an input layer, a hidden layer, and an output layer.</p>
<p><img src="/posts/images/copied_from_nb/images/neural-network.png" alt=""></p>
<p>The input layer receives an input signal to be processed. The model's prediction is performed by the output layer. The hidden layers between the input and output layer are the computational engine of the model. MLPs can be used to approximate any continuous function, and can solve problems which are not linearly separable by using non-linear activation functions.</p>
<p><img src="/posts/images/copied_from_nb/images/neuron.jpeg" alt=""></p>
<p>An MLP learns in two stages:</p>
<ul>
<li>
<strong>Forward propagation</strong>, where data is fed from the input layer through the hidden layers to the output layer. For a general model of $L$ layers with weights $W$ and activation functions $\sigma$, forward propagation can be expressed as a function composition as shown:
$$
F(x) = \sigma_N(W_L\cdot \sigma_{L-1}(W_{L-1}\cdots \sigma_2(W_2\cdot \sigma_1(W_1\cdot x))\cdots))\\
$$</li>
<li>
<p><strong>Backpropagation</strong>, where by using the chain rule, the partial derivatives of the loss function w.r.t. the various weights and biases are fed back through the network from the output layer through to the input layer. The differentiation produces a gradient along which the parameters may be adjusted towards the minima. See <strong>Backpropagation algorithm</strong> for more detail.</p>
<p><img src="images/sgd.png" alt=""></p>
</li>
</ul>
<p>These stages are repeated until the loss converges towards a minimum.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Backpropagation-algorithm">
<a class="anchor" href="#Backpropagation-algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Backpropagation algorithm<a class="anchor-link" href="#Backpropagation-algorithm"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Backpropagation is a widely used algorithm for training feed-forward neural networks used to compute the gradient of a loss function with respect to the weights of a network for a training set of input-output examples. The gradient computed by backpropagation can be used with other algorithms such as Stochastic Gradient Descent (or its derivatives) to update the weights and minimise error in a network.</p>
<p>Below shows the mathematical logic behind the algorithm. The following example is for a feed-forward network of $L$ layers.</p>
$$
F(x) = \sigma_N(W_L\cdot \sigma_{L-1}(W_{L-1}\cdots \sigma_2(W_2\cdot \sigma_1(W_1\cdot x))\cdots))\\
Cost = J(y, F(x))
$$<p>For the model above, the derivative of the loss w.r.t. the input $x$ using the chain rule is generalised as such:
$$
\text{Chain rule}: \\F(x) = f(g(x)) \qquad F'(x) = f'(g(x)) \cdot g'(x) \\
\text{derivative of compound function} = \text{derivative of outer function} \times \text{derivative of inner function}\\[1em]
\therefore\quad\frac{dJ}{dx} = \frac{dJ}{da_L} \circ \sigma_L' \cdot W_L \circ \sigma_{L-1}' \cdot W_{L-1} \cdots \circ \sigma_1' \cdot W_1
$$
The gradient $\nabla$ is the transpose of the derivative of the loss w.r.t. the input, therefore, the matrices are transposed and the order of multiplication is reversed, such that:
$$
\nabla_xJ = W_1^T \cdot \sigma_1' \cdots \circ W_{L-1}^T \cdot \sigma_{L-1}' \circ W_L^T \cdot \sigma_L' \circ \nabla_{a_L}J
$$
The backpropagation consists of then evaluating this expression from right to left, i.e starting from the output layer, computing the gradient at each layer on the way. To avoid unneccessary repeated computation of expressions, we can introduce a new variable $\delta_l$, the "error at layer $l$". This variable is a vector with length of the number of nodes in its associated layer. Each value can be interpreted as the loss attributable to that node for the given input-output sample. $\delta_l$ can then be computed recursively, starting backwards from layer $L \rightarrow 1$, such that:
$$\delta_{l-1} := \sigma_{l-1}' \circ W_l^T \cdot \delta_l$$ 
The gradients of the weights can then be calculated, such that:

$$\nabla_{W_l}J = \delta_l \cdot a_{l-1}^T$$

Finally, the weights be updated (demonstrated here with stochastic gradient descent), such that:
$$
W_l := W_l - \eta \cdot \nabla_{W_l}J\\
$$</p>
<p>Where,<br>
$L$ : Number of layers in network<br>
$\sigma$ : Non-linear activation function<br>
$J$ : Loss function taking parameters $y$ (expected output), and $\hat y$ (actual output)<br>
$W_l$ : Weight matrix of $l$<sup>th</sup> layer; all the connections between nodes in current and next layer.<br>
$a_l$ : Activated output of $l$<sup>th</sup> layer<br>
$\delta_l$ : Error at $l$<sup>th</sup> layer<br>
$\eta$ : Learning rate of SGD algorithm<br>
$A^T$ : Transpose of matrix $A$<br>
$\nabla_ba$ : Gradient of $a$ w.r.t $b$<br>
$\circ$ : Hadamard (element-wise) matrix multiplication, products taken from left to right</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CART-algorithm">
<a class="anchor" href="#CART-algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>CART algorithm<a class="anchor-link" href="#CART-algorithm"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The CART (Classification and Regression Tree) algorithm is a divide-and-conquer algorithm used to build a decision tree (as a predictive model) to predict the output of a given sample, using attributes observed in a given training set. The model is very intuitive and easy to interpret/explain. Furthermore, it is robust and does not require any prior normalisation or scaling of the dataset. It is also unaffected by outliers and finds important variables automatically, unlike linear regression models. However, decision trees are prone to overfitting, and small changes to the dataset can cause a large change in tree structure causing instability. The algorithm, while can be modelled to perform the task, is inadequate for applying regression and predicting continuous values, and cannot extrapolate beyond its observed set. To mitigate some of these issues, decision trees are often used in ensemble methods including random forests and gradient boosting machines, which aim to reduce overfitting.</p>
<p>The algorithm performs binary splits using the features of a dataset to build a tree, until all of the nodes are ideally "pure".</p>
<p><img src="https://bookdown.org/tpinto_home/Beyond-Additivity/tree.png" alt=""></p>
<p>Optimal splits are found by comparing the impurity of multiple potential splits. Popular metrics used to measure impurity are:</p>
<ul>
<li>
<p>Gini impurity (classification) - calculates the probability that a specific feature is classified incorrectly when selected randomly. A pure node of gini index 0 indicates that all its contained elements are of one unique class.
$$
\textit{Gini} = 1 - \sum^n_{k=1}P_k^2
$$
Where $P_i$ is the probability of class $k$.</p>
</li>
<li>
<p>Variance reduction (regression) - variance is used for calculating the homogeneity of a node. If a node is entirely homogeneous, i.e pure, then the variance is zero.
$$
\textit{Var}(y) = \frac 1n\sum^n_{i=1}(y_i-\bar y)^2\\
$$
Where $\bar y$ is the mean of input data $y$</p>
</li>
</ul>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Entropy-illustration.png/422px-Entropy-illustration.png" alt=""></p>
<p>To determine the quality of a split using some impurity metric, we use information gain, which can be described as the reduction of information entropy $H$ from a prior state (parent node) to a new state (split into children nodes):
$$
\text{Gain} = \text{Entropy of parent node} - \text{Average entropy of children nodes}\\
IG(p,l,r) = H(p) - \frac 1{n_p} (n_lH(l) + n_rH(r)) 
$$
Where,<br>
$p$: parent node<br>
$l$: left subtree<br>
$r$: right subtree<br>
$n_x$: number of elements in a set $x$<br>
$H(x)$: entropy metric function</p>
<p>The algorithm starts at the root node, with the entire dataset. It then compares potential splits (all permutations of features and unique thresholds) and chooses the split with the highest information gain. It then recursively repeats this process on the its resulting splits until the nodes are pure, or until the process is stopped manually. The algorithm is stopped by user specified parameters, such as when the tree grows to a maximum depth provided or if a split produces a minimum number of samples.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Random-forest">
<a class="anchor" href="#Random-forest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random forest<a class="anchor-link" href="#Random-forest"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Random forests are a bagging ensemble learning method which construct multiple decision trees at training time.  In the bagging method, also known as bootstrap aggregation, a random sample from the training set is selected with replacement - allowing data points to be used multiple times. After several data samples are generated, a number of estimators are then individually trained. When making a prediction, outputs from each indiviual tree are aggregated to yield a more accurate result; for regression the mean is taken, and for classification the majority vote.</p>
<p><img src="/posts/images/copied_from_nb/images/random-forest.jpg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Gradient-boosting-machine">
<a class="anchor" href="#Gradient-boosting-machine" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gradient boosting machine<a class="anchor-link" href="#Gradient-boosting-machine"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Gradient boosting is a boosting ensemble learning method that combines a set of weak learners (decision trees) into a single strong learner to minimise training errors. In boosting, a random sample of data is selected, fitted with a model and trained sequentially; each model tries to improve the errors of its predecessor, by training on the previous predictor's residual errors. The method combines both the gradient descent and boosting methods, hence the name gradient boosting.</p>
<p><img src="/posts/images/copied_from_nb/images/gradient-boosting.png" alt=""></p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/posts/house-prices/2022/05/08/p1-analysis.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/posts/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/posts/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/posts/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/posts/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/posts/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
